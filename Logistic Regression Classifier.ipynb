{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import theano.tensor as T\n",
    "from theano import function, shared, pp\n",
    "import theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading data\n",
      "Building the model...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Function' object has no attribute 'owner'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-9550f7b0583f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[0mpp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m \u001b[0msgd_optimization_mnist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-29-9550f7b0583f>\u001b[0m in \u001b[0;36msgd_optimization_mnist\u001b[1;34m(learning_rate, epochs, dataset, batch_size)\u001b[0m\n\u001b[0;32m    177\u001b[0m     )\n\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m     \u001b[0mpp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[0msgd_optimization_mnist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/grady/code/learning/theano/lib/python3.4/site-packages/theano/printing.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    498\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 500\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    501\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mPrinterState\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/grady/code/learning/theano/lib/python3.4/site-packages/theano/printing.py\u001b[0m in \u001b[0;36mprocess\u001b[1;34m(self, r, pstate)\u001b[0m\n\u001b[0;32m    433\u001b[0m             \u001b[0mpstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPrinterState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpprinter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcondition\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprinter\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprinters\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mcondition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/grady/code/learning/theano/lib/python3.4/site-packages/theano/printing.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(pstate, r)\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m             \u001b[0mop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcondition\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m             condition = (lambda pstate, r: r.owner is not None\n\u001b[0m\u001b[0;32m    426\u001b[0m                          and r.owner.op == op)\n\u001b[0;32m    427\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprinters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprinter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Function' object has no attribute 'owner'"
     ]
    }
   ],
   "source": [
    "class LogisticRegression():\n",
    "    def __init__(self, input, input_dimensions, output_dimensions):\n",
    "        self.weights = shared(\n",
    "            value=np.zeros(\n",
    "                (input_dimensions, output_dimensions),\n",
    "                dtype=theano.config.floatX\n",
    "            ),\n",
    "            name='weights',\n",
    "            borrow=True\n",
    "        )\n",
    "        self.bias = shared(\n",
    "            value=np.zeros(\n",
    "                (output_dimensions,),\n",
    "                dtype=theano.config.floatX\n",
    "            ),\n",
    "            name='bias',\n",
    "            borrow=True\n",
    "        )\n",
    "        self.p_label_given_features = T.nnet.softmax(T.dot(input, self.weights) + self.bias)\n",
    "        self.label_prediction = T.argmax(self.p_label_given_features, axis=1)\n",
    "        self.params = [self.weights, self.bias]\n",
    "    \n",
    "    def negative_log_likelihood(self, labels):\n",
    "        # T.log(self.p_label_given_features) is a matrix where each row is an example\n",
    "        # and each column is a class, and each element is the log probability of that\n",
    "        # example being in that class.\n",
    "        # T.log(self.p_label_given_features)[T.arange(labels.shape[0]),labels)]\n",
    "        # is a vector where each element is the log probability of the correct label given\n",
    "        # the model.\n",
    "        return -T.mean(T.log(self.p_label_given_features)[T.arange(labels.shape[0]), labels])\n",
    "    \n",
    "    def errors(self, labels):\n",
    "        if labels.ndim != self.label_prediction.ndim:\n",
    "            raise TypeError(\"labels should have the same shape as self.label_prediction\",\n",
    "                            ('labels', labels.type, 'label_prediction', self.label_prediction.type))\n",
    "        if labels.dtype.startswith('int'):\n",
    "            return T.mean(T.neq(self.label_prediction, labels))\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "# Copy and pasted. Not tryna deal with this.          \n",
    "def load_data(dataset):\n",
    "    ''' Loads the dataset\n",
    "\n",
    "    :type dataset: string\n",
    "    :param dataset: the path to the dataset (here MNIST)\n",
    "    '''\n",
    "\n",
    "    #############\n",
    "    # LOAD DATA #\n",
    "    #############\n",
    "\n",
    "    # Download the MNIST dataset if it is not present\n",
    "    data_dir, data_file = os.path.split(dataset)\n",
    "    if data_dir == \"\" and not os.path.isfile(dataset):\n",
    "        # Check if dataset is in the data directory.\n",
    "        new_path = os.path.join(\n",
    "            os.path.split(__file__)[0],\n",
    "            \"..\",\n",
    "            \"data\",\n",
    "            dataset\n",
    "        )\n",
    "        if os.path.isfile(new_path) or data_file == 'mnist.pkl.gz':\n",
    "            dataset = new_path\n",
    "\n",
    "    if (not os.path.isfile(dataset)) and data_file == 'mnist.pkl.gz':\n",
    "        import urllib\n",
    "        origin = (\n",
    "            'http://www.iro.umontreal.ca/~lisa/deep/data/mnist/mnist.pkl.gz'\n",
    "        )\n",
    "        print('Downloading data from %s' % origin)\n",
    "        urllib.urlretrieve(origin, dataset)\n",
    "\n",
    "    print('... loading data')\n",
    "\n",
    "    # Load the dataset\n",
    "    f = gzip.open(dataset, 'rb')\n",
    "    train_set, valid_set, test_set = pickle.load(f, encoding='latin1')\n",
    "    f.close()\n",
    "    #train_set, valid_set, test_set format: tuple(input, target)\n",
    "    #input is an numpy.ndarray of 2 dimensions (a matrix)\n",
    "    #witch row's correspond to an example. target is a\n",
    "    #numpy.ndarray of 1 dimensions (vector)) that have the same length as\n",
    "    #the number of rows in the input. It should give the target\n",
    "    #target to the example with the same index in the input.\n",
    "\n",
    "    def shared_dataset(data_xy, borrow=True):\n",
    "        \"\"\" Function that loads the dataset into shared variables\n",
    "\n",
    "        The reason we store our dataset in shared variables is to allow\n",
    "        Theano to copy it into the GPU memory (when code is run on GPU).\n",
    "        Since copying data into the GPU is slow, copying a minibatch everytime\n",
    "        is needed (the default behaviour if the data is not in a shared\n",
    "        variable) would lead to a large decrease in performance.\n",
    "        \"\"\"\n",
    "        data_x, data_y = data_xy\n",
    "        shared_x = theano.shared(np.asarray(data_x,\n",
    "                                            dtype=theano.config.floatX),\n",
    "                                 borrow=borrow)\n",
    "        shared_y = theano.shared(np.asarray(data_y,\n",
    "                                            dtype=theano.config.floatX),\n",
    "                                 borrow=borrow)\n",
    "        # When storing data on the GPU it has to be stored as floats\n",
    "        # therefore we will store the labels as ``floatX`` as well\n",
    "        # (``shared_y`` does exactly that). But during our computations\n",
    "        # we need them as ints (we use labels as index, and if they are\n",
    "        # floats it doesn't make sense) therefore instead of returning\n",
    "        # ``shared_y`` we will have to cast it to int. This little hack\n",
    "        # lets ous get around this issue\n",
    "        return shared_x, T.cast(shared_y, 'int32')\n",
    "\n",
    "    test_set_x, test_set_y = shared_dataset(test_set)\n",
    "    valid_set_x, valid_set_y = shared_dataset(valid_set)\n",
    "    train_set_x, train_set_y = shared_dataset(train_set)\n",
    "\n",
    "    rval = [(train_set_x, train_set_y), (valid_set_x, valid_set_y),\n",
    "            (test_set_x, test_set_y)]\n",
    "    return rval\n",
    "\n",
    "def nth_batch(data_set, batch_size, index):\n",
    "    return data_set[index * batch_size : (1 + index) * batch_size]\n",
    "\n",
    "def sgd_optimization_mnist(learning_rate=0.13, epochs=1000, dataset='mnist.pkl.gz', batch_size=600): \n",
    "    datasets = load_data(dataset)\n",
    "    \n",
    "    train_set_features, train_set_labels = datasets[0]\n",
    "    validation_set_features, validation_set_labels = datasets[1]\n",
    "    test_set_features, test_set_labels = datasets[2]\n",
    "    \n",
    "    train_batches_count = train_set_features.get_value(borrow=True).shape[0] // batch_size\n",
    "    validation_batches_count = validation_set_features.get_value(borrow=True).shape[0] // batch_size\n",
    "    train_batches_count = train_set_features.get_value(borrow=True).shape[0] // batch_size\n",
    "    \n",
    "    print(\"Building the model...\")\n",
    "    \n",
    "    index=T.lscalar()\n",
    "    \n",
    "    data_features = T.matrix('data_features')\n",
    "    data_labels = T.ivector('data_labels')\n",
    "\n",
    "    classifier = LogisticRegression(input=data_features, input_dimensions=28*28, output_dimensions=10)\n",
    "\n",
    "    cost = classifier.negative_log_likelihood(data_labels)\n",
    "    \n",
    "    test_model = function(\n",
    "        inputs=[index],\n",
    "        outputs=classifier.errors(data_labels),\n",
    "        givens={\n",
    "            data_features: nth_batch(test_set_features, batch_size, index),\n",
    "            data_labels: nth_batch(test_set_labels, batch_size, index)\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    validate_model = function(\n",
    "        inputs=[index],\n",
    "        outputs=classifier.errors(data_labels),\n",
    "        givens={\n",
    "            data_features: nth_batch(validation_set_features, batch_size, index),\n",
    "            data_labels: nth_batch(validation_set_labels, batch_size, index)\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    weights_gradient = T.grad(cost=cost, wrt=classifier.weights)\n",
    "    bias_gradient = T.grad(cost=cost, wrt=classifier.bias)\n",
    "\n",
    "    updates = [(classifier.weights, classifier.weights - learning_rate * weights_gradient),\n",
    "               (classifier.bias, classifier.bias - learning_rate * bias_gradient)]\n",
    "    \n",
    "    train_model = function(\n",
    "        inputs=[index],\n",
    "        outputs=cost,\n",
    "        updates=updates,\n",
    "        givens={\n",
    "            data_features: nth_batch(train_set_features, batch_size, index),\n",
    "            data_labels: nth_batch(train_set_labels, batch_size, index)\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    pp(train_model)\n",
    "\n",
    "sgd_optimization_mnist()\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
